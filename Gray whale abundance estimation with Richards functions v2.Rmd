---
title: "A new approach to gray whale abundance estimation"
author: "Tomo Eguchi"
date: "`r Sys.Date()`"
output: 
  bookdown::word_document2: default
---


```{r setup, include=FALSE}
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
save.fig <- F

source("Granite_Canyon_Counts_fcns.R")
library(tidyverse)
library(lubridate)
library(flextable)
library(jagsUI)
library(bayesplot)
library(ggpubr)
library(R2WinBUGS)
library(abind)

set_flextable_defaults(font.size = 9,
                       font.family = "Cambria")

dpi.set <- 300

plots.trace <- function(jm, params, params.df = NULL){
  out.list <- list()
  for (i in 1:length(params)){
    
    p.tmp <- mcmc_trace(jm$samples, params[i]) +
        legend_none() + xaxis_text(on = FALSE)
      
      if (!is.null(params.df)){
        if (!is.na(params.df[i, "value"])){
        p.tmp <- p.tmp + 
          hline_at(params.df[i, "value"], 
                   color = "red", size = 1.2)
          
        }
      }
      
    out.list[[i]] <- p.tmp 
  }
  return(out.list)
}

plots.dens <- function(jm, params){
  out.list <- list()
  for (k in 1:length(params)){
    out.list[[k]] <- mcmc_dens(jm$samples, params[k]) #+

  }
  
  return(out.list)
}

```

## Introduction {-}

Analytical methods to estimate abundance of gray whales from visual surveys at Granite Canyon, CA, have evolved over the years. Laake et al. (2006?) used the distance sampling approach with generalized additive models (GAMs). Durban et al. (2016) developed a new method using a Bayesian N-mixture approach. The new approach was approved by the IWC and it has been used for the analysis since the 2015/2016 season. The analysis is conducted using WinBUGS, which has become obsolete over the last several years. In this report, I provide improvements of the method by Durban et al. where the analysis is conducted using JAGS (Plummer 2021), which is a widely used Bayesian programming language. 

The general tendency of annual migration of gray whales (or any other migratory species - find other examples) is that when the migration is observed at a location along the migration corridor, the number increases over time until it reaches its peak, then it decreases. The method by Durban et al. used a Gaussian function to capture this general trend. 

In the following, I first describe the method by Durban et al. and point out underlying assumptions that are somewhat questionable. Then, I introduce a new approach that is consistent with the basic idea of the method by Durban et al. but improve it by removing those assumptions. I show the performance of the new approach using simulated data. Finally, I reanalyze the data to compare abundance estimates between the two approaches. 


## Method by Durban et al. {-}

### Mathematical description {-}


### Difficulties of the method {-}

The approach used the "cut" function within WinBUGS to select either Gaussian or spline fit to daily count of gray whales. The use of "cut" function has been criticized (Plummer YR). Furthermore, the assumption that the number of gray whales migrating in front of the observation station follows a Gaussian function is somewhat questionable. The true curve may not be symmetrical around the peak and the peak may not be instantaneous. In other words, the peak may persist for a few days. Fitting spline functions to observed counts alleviates the problem but it loses the general idea that the number of whales increases, reaches a peak, then decreases over the migration season.  

## Improvements {-}

### Model description
In order to overcome these difficulties with the previous approach, I propose to use a more flexible function that can accommodate the general shape (increase, peak then decrease) and asymmetrical around the peak. The function is often called Richards' function and it has the following form.

$$M_1 = (1 + (2 e^K - 1) * e^{(P-d)/(S_1)}) ^ {(-1/e^K)}$$

$$M_2 = (1 + (2 e^K - 1) * e^{(P-d)/(S_2)}) ^ {(-1/e^K)}$$

$$N = N_{min} + (N_{max} - N_{min}) * (M_1 * M_2),$$ 

where $d$ is the number of days from the beginning of nesting season,

$S_1 < 0$ and $S_2 > 0$ defines how the slope decreases and increases, respectively,

$K > 0$ defines the "flatness" at the peak of the function,

$P$ defines where the peak is relative to the range of $d$, where $min(d) < P < max(d)$,

$N_{min}$ is zero, i.e., the number of whales migrating outside of a migration season and,

$N_{max} >> N_{min}$. $N_{max}$ is not the maximum number of whales migrating per day but it is a parameter that may be fixed or estimated during the analysis.  


### Function characteristics {-}

#### Effects of $S_1$ {-}

The parameter $S_1 < 0$ defines how the curve decreases from its peak. The rate of decline slows down as $S_1$ becomes smaller (Figure \@ref(fig:Figure-S1)). Because we make an assumption that there are no whales migrating at day 1 and 90, the lower bound of $S_1$ can be restricted to a certain value, e.g., -5).   

```{r S1, echo=FALSE, message=FALSE}
S1 <- c(-10, -5, -2.5, -1.2, -0.6, -0.3)
S2 <- 1.5
K <- 1
P <- 40
max.N <- 800

true.mean.N <- matrix(data = 0, nrow = 90, ncol = length(S1))

for (c in 1:length(S1)){
  for (d in 1:90){
    true.mean.N[d, c] <- floor(Richards_fcn(d = d, 
                                            S1 = S1[c], 
                                            S2 = S2,
                                            K = K, 
                                            P = P, 
                                            min = 0, max = max.N)  )
    

  }
  
}

data.df <- data.frame(Day = rep(1:90, times = length(S1)),
                      mean.N = as.vector(true.mean.N),
               
                      S1 = rep(S1, each = 90))

p.S1 <- ggplot(data = data.df) +
  geom_path(aes(x = Day, y = mean.N), color = "red") +

  facet_wrap(~ S1)

if (save.fig)
  ggsave(p.S1, 
         filename = paste0("figures/S1_", dpi.set, "dpi.png"), 
                           dpi = dpi.set, device = "png")

```



```{r Figure-S1, echo=FALSE, message=FALSE, fig.cap="Effects of $S_1$. In this example, $S_2 = 1.5$, $K = 1$, $P = 40$, $N_{max} = 800$."}

knitr::include_graphics(paste0("figures/S1_", dpi.set, "dpi.png"))

```


#### Effects of $S_2$ {-}

The parameter $S_2 > 0$ defines how the curve increases to its peak. The rate of increase slows down as $S_2$ becomes larger (Figure \@ref(fig:Figure-S2)). Because we make an assumption that there are no whales migrating at day 1 and 90, the upper bound of $S_2$ can be restricted to a certain value, e.g., 5).

```{r S2, echo=FALSE, message=FALSE}
S1 <- -1.5
S2 <- c(0.3, 0.6, 1.2, 2.5, 5, 10)
K <- 1
P <- 40
max.N <- 800

true.mean.N <- matrix(data = 0, nrow = 90, ncol = length(S2))

for (c in 1:length(S2)){
  for (d in 1:90){
    true.mean.N[d, c] <- floor(Richards_fcn(d = d, 
                                            S1 = S1, 
                                            S2 = S2[c],
                                            K = K, 
                                            P = P, 
                                            min = 0, max = max.N)  )
    
  }
  
}

data.df <- data.frame(Day = rep(1:90, times = length(S2)),
                      mean.N = as.vector(true.mean.N),

                      S2 = rep(S2, each = 90))

p.S2 <- ggplot(data = data.df) +
  geom_path(aes(x = Day, y = mean.N), color = "red") +

  facet_wrap(~ S2)

if (save.fig)
  ggsave(p.S2, filename = paste0("figures/S2_", dpi.set, "dpi.png"), 
         dpi = dpi.set, device = "png")

```


```{r Figure-S2, echo=FALSE, message=FALSE, fig.cap="Effects of $S_2$. In this example, $S_1 = -1.5$, $K = 1$, $P = 40$, $N_{max} = 800$."}

knitr::include_graphics(paste0("figures/S2_", dpi.set, "dpi.png"))

```


#### Effects of K {-}

The parameter $K > 0$ defines the flatness of the curve at its peak. Greater $K$ values correspond to flatter peaks (Figure \@ref(fig:Figure-K)). Similarly to $S_1$ and $S_2$, the upper bound of $K$ may be defined based on the assumption that the numbers of migrating gray whales are zero at day 1 and 90, e.g., $K < 2$. 

```{r K, echo=FALSE, message=FALSE}
S1 <- -2.5
S2 <- 2.5
K <- c(0.01, 0.1, 1, 2, 4, 8)
P <- 40
max.N <- 800

true.mean.N <- matrix(data = 0, nrow = 90, 
                           ncol = length(K))

for (c in 1:length(K)){
  for (d in 1:90){
    true.mean.N[d, c] <- floor(Richards_fcn(d = d, 
                                            S1 = S1, 
                                            S2 = S2,
                                            K = K[c], 
                                            P = P, 
                                            min = 0, max = max.N)  )
    
  }
  
}

data.df <- data.frame(Day = rep(1:90, times = length(K)),
                      mean.N = as.vector(true.mean.N),
                      K = rep(K, each = 90))

p.K <- ggplot(data = data.df) +
  geom_path(aes(x = Day, y = mean.N), color = "red") +
  facet_wrap(~ K)

if (save.fig)
  ggsave(p.K, filename = paste0("figures/K_", dpi.set, "dpi.png"), 
         dpi = dpi.set, device = "png")

```


```{r Figure-K, echo=FALSE, message=FALSE, fig.cap="Effects of $K$. In this example, $S_1 = -2.5$, $S_2 = 2.5$, $P = 40$, $N_{max} = 800$."}

knitr::include_graphics(paste0("figures/K_", dpi.set, "dpi.png"))

```



#### Effects of P {-}

The parameter $P$ defines the location of its peak (Figure \@ref(fig:Figure-P)). 

```{r P, echo=FALSE, message=FALSE}
S1 <- -2.5
S2 <- 2.5
K <- 1.5
P <- c(20, 40, 60, 80)
max.N <- 800

true.mean.N <- matrix(data = 0, nrow = 90, 
                           ncol = length(P))

for (c in 1:length(P)){
  for (d in 1:90){
    true.mean.N[d, c] <- floor(Richards_fcn(d = d, 
                                            S1 = S1, 
                                            S2 = S2,
                                            K = K, 
                                            P = P[c], 
                                            min = 0, max = max.N)  )
    
  }
  
}

data.df <- data.frame(Day = rep(1:90, times = length(P)),
                      mean.N = as.vector(true.mean.N),
                      P = rep(P, each = 90))

p.P <- ggplot(data = data.df) +
  geom_path(aes(x = Day, y = mean.N), color = "red") +
  facet_wrap(~ P)

if (save.fig)
  ggsave(p.P, filename = paste0("figures/P_", dpi.set, "dpi.png"), 
                                dpi = dpi.set, device = "png")

```


```{r Figure-P, echo=FALSE, message=FALSE, fig.cap="Effects of $P$. In this example, $S_1 = -2.5$, $S_2 = 2.5$, $K = 1.5$, $N_{max} = 800$."}

knitr::include_graphics(paste0("figures/P_", dpi.set, "dpi.png"))

```


#### Fitting the model to observed counts {-}

The proposed new approach replaces the spline-Gaussian selection step in Durban et al. with Richards functions. The observed counts are modeled with binomial distributions as it was in Durban et al.

$$ n_{d_t,s,y} \sim BIN(N_{t, y}, p_{d_t, s, y} * \theta_{d_t, y}) $$
where $n_{d_t, s, y}$ is the observed number of gray whales during the watch period $d$ of the $t$-th day of the season $y$ from the station $s$, $N_{t, y}$ is the number of gray whales that migrated through the sampling area during the $t$-th day,  $p_{d_t, s, y}$ is the sighting probability of the station $s$ during the watch period $d$ of the $t$-th day of the season $y$, and $\theta_{d_t,y}$ is the fractional duration of the watch period $d_t$ to the total possible (9 hrs), e.g., 3 hrs equals to 3/9 = 0.3.

The sighting probability $p_{d_t, s, y}$ is modeled as a function of Beaufort sea state, visibility, and observers. Beaufort sea state and visibility were treated as fixed effects, whereas observers were treated as a random effect. Furthermore, additional parameters were added to determine whether or not to include any of these covariates. 


$$ logit(p_{d_t, s, y}) = \beta_0 + I_{BF} * \beta_{BF} * BF_{d_t, y} + I_{VS} * \beta_{VS} * VS_{d_t, y} + I_{OBS} * OBS_{d_t, s, y}  $$

This is identical to how the sighting probability was modeled in Durban et al. (2016).


The number of gray whales that migrated through the sampling area during the $t$-th day of the season was modeled as a random Poisson variable with the mean $\bar{N}_{t, y}$, 

$$ N_{t, y} \sim POI(\bar{N}_{t,y}) $$

where $\bar{N}_t$ is the "mean" number of whales that expected to migrate through the sampling area on the $t$-th day of the season $y$ and modeled with Richards functions above. 

I used Poisson distribution for this hierarchical model based on the finding in Raftery (1988). 

The total number of gray whales for season $y$ is the sum of all $N_{t, y}$ and corrected for nighttime passage:

$$ N_y = \lambda * \sum_{t = 1} ^ {90} N_{t, y} $$ and 

$$ \lambda \sim N(1.0875, 0.03625) $$ (Perryman et al. YR). 



### Performance of the proposed approach

#### Simulation

To evaluate the performance of the new approach using Richards functions, I simulated data using the above relationships. To test for a mismatch between the within-season mean function between the true and model (i.e., Richards function), daily mean numbers of whales ($\bar{N}_{y,t}$, $y = 1, 2$, $t = 1, \dots, 90$) for the first year was simulated from a gamma distribution function (GAM(3, 0.07) * 5000). For the second year, I used Richards function (R()) for the daily mean numbers.  

$$ \bar{N}_{1,t} = GAM(t, 3, 0.07) $$, and 

$$ \bar{N}_{2,t} = R(t, S_1 = -0.9, S_2 = 1.5, P = 48, K = 2.5, max = 200) $$, 

where $t = 1, \dots, 90$.

The shape of the gamma function is shown in Figure \@ref(fig:Figure-Gam-def).

```{r mean-N-fcns, echo=FALSE, message=FALSE}
alpha.gam <- 5.4
beta.gam <- 0.13
multip.gam <- 6000
gam.def <- data.frame(x = seq(0, 100, by = 0.01)) %>%
  mutate(y = dgamma(x, alpha.gam, beta.gam) * multip.gam)

p.gam.def <- ggplot(gam.def) +
  geom_path(aes(x = x, y = y))+ 
  ylab(latex2exp::TeX(sprintf("$\\bar{N}$")))

S1 <- 0.9  # this gets fixed to a negative value in Richards_fcn. 
S2 <- 1.5
P <- 48
K <- 2.5
Max <- 200
Richards.def <- Richards_fcn(d =  seq(0, 100, by = 0.01), 
                            S1 = S1, 
                            S2 = S2,
                            K = K, 
                            P = P, 
                            min = 0, max = Max)

p.Richards.def <- ggplot(data.frame(x = seq(0, 100, by = 0.01),
                                    y = Richards.def)) +
  geom_path(aes(x = x, y = y)) + 
  ylab(latex2exp::TeX(sprintf("$\\bar{N}$")))

p.mean.N.def <- cowplot::plot_grid(plotlist = list(p.gam.def, p.Richards.def), 
                            ncol = 2)

if (save.fig)
  ggsave(filename = paste0("figures/mean_N_def_", dpi.set, "dpi.png"), 
         plot = p.mean.N.def,
         device = "png", dpi = dpi.set)
```

Daily true numbers of gray whales that migrated through the sampling area then were simulated using a Poisson distribution with the daily mean values:

$$ n_{y,t} \sim POI(\bar{N}_{y,t})  $$

Finally, the recorded numbers of whales by the observers ($m_{y,t,i}$) were simulated using a binomial distribution with the true number of gray whales ($\n_{y,t}$) and the sighting probability ($p_{y,t,i}$), for the i-th observation period on day t, where the index of observation periods in a day can range from 1 to 6. The actual index of observation periods is inconsequential, however. Sighting probability for one period is treated as a function of (1) viewing condition (V), (2) Beaufort sea state (B), (3) the observation duration as a fraction of maximum ($q_{t,y,i}$; 6 periods equal to 540 minutes), and (4) observer random effects ($O_{t,y,i}$). If an observation period lasted 34 minutes, $q_{t,y,i}$ = 34/540

$$ logit(\gamma_{y,t,i}) = \bar{p} + I(V) \beta_{V} V_{y,t,i} + I(B) \beta_{B} B_{y,t,i} + I(O) O_{y,t,i} $$.

I(.) is an indicator function (either 0 or 1) that is used to determine whether or not to include each term. Sighting probability, then is multiplied by the observation duration proportion for the day ($q_{t,y,i}$).

$$ p_{y,t,i} = \gamma_{y,t,i} \times q_{t,y,i} $$

Finally, the observed number of whales was simulated using a binomial distribution. 

$$ m_{y,t,i} \sim BIN(n_{y,t}, p_{y,t,i}) $$

In this simulation, the total number of whales per year was not simulated directly. Rather, daily numbers of whales were simulated from the mean curves (Gamma or Richards). The total number of gray whales during daily observation window (540 minutes) was multiplied by a correction factor (mean = 1.0875, S = 0.03625) and summed over 90 days to obtain the corrected total number of whales in one year. 


```{r Figure-Gam-def, echo=FALSE, message=FALSE, fig.cap="The shapes of $\bar{N}$ for simulated data. A gamma distribution function was used for the first year (left) and Richards function for the second year. Although there are non-zero values at x = 1 and beyond x = 90, the $\bar{N}$ was fixed to 0 at x = 1 and 90."}

knitr::include_graphics(paste0("figures/mean_N_def_", dpi.set, "dpi.png"))

```


```{r simulation, echo=FALSE, message=FALSE}
set.seed(12345)
#save.fig <- T

# Define Richards function parameters
Days <- 1:90

# Alternatively, use a different function to create real values for the means
N.mean <- matrix(nrow = 90, ncol = 2)

# first year with gamma
N.mean[,1] <- dgamma(1:90, alpha.gam, beta.gam) * multip.gam

# second year with Richards functions
N.mean[,2] <- Richards_fcn(d = Days, S1 = S1, S2 = S2, 
                           K = K, P = P, min = 0, max = Max)

# This is by assumption
#N.mean[c(1,90), 1:2] <- 0

# Define sighting probability parameters
B0 <- 0.7
B_BF <- -1.2
B_VS <- -1.8

Season = c("2020", "2022")

True.N <- matrix(nrow = 90, ncol = length(Season))
for (k in 1:nrow(N.mean)) {
  for (c in 1:ncol(N.mean)){
    True.N[k,c] <- rpois(n = 1, lambda = N.mean[k, c])
  }
  
}

# Force True.N = 0 for day 1 and 90
True.N[1,] <- True.N[90,] <- 0

# Use real data for observers, Beaufort, and visibility
set.seed(12345)
Data_True.N <- list()
periods <- vector(mode = "numeric", length = length(Season))

# need to convert observer initials into numbers for all years
obs.list <- read.csv(file = "Data/Observer list 2022.csv")

for (y in 1:length(Season)){
  # I use the real data to emulate sampling and sighting conditions
  tmp <- readRDS(paste0("RData/V2.1_Aug2022/out_", Season[y], "_Tomo_v2.rds"))
  Final_Data <- tmp$Final_Data %>%
    mutate(Year = Season[y],
           Day = as.numeric(BeginDay)) %>%
    mutate(effort = dur) %>%
    mutate(watch.prop = effort * 24/9) %>%
    select(Year, Day, effort, watch.prop, bf, vs, n, obs) %>%
    filter(bf < 5, vs < 5)
  
  # Find all observers and change them into integer code.
  # These numbers have to be consistent over years.
  obs.y <- data.frame(obs = Final_Data$obs) %>% 
    left_join(obs.list, by = "obs") 
  
  Final_Data$obs.ID <- obs.y$ID
  
  # unique.obs <- unique(obs.y$ID)
  # obs.ID.df <- data.frame(obs = obs.list[obs.list$ID %in% unique.obs, "obs"],
  #                         obs.ID = unique.obs) %>%
  #   arrange(by = obs.ID)
  # 
  # Final_Data %>% 
  #   left_join(obs.ID.df, by = "obs") %>% 
  #   select(-obs) -> Final_Data
  
  # figure out the number of periods
  Final_Data %>% 
    group_by(Year) %>%
    #filter(effort > 0) %>%
    summarise(n = n()) -> n.days
  
  periods[y] <- n.days$n
  
  Final_Data$n[Final_Data$effort == 0] <- NA
  
  # Create sighting probabilities
  Final_Data %>%
    mutate(Sighting.Prob.lm = as.vector(B0 + B_BF * scale(bf) + 
                                          B_VS * scale(vs)),
           Sighting.Prob = exp(Sighting.Prob.lm)/(1 + exp(Sighting.Prob.lm)),
           Binom.Prob = watch.prop * Sighting.Prob) -> Final_Data
  
  Final_Data %>%
    left_join(data.frame(Day = Days,
                         N.mean = N.mean[,y],
                         N.True = True.N[,y]), 
              by = "Day") -> Data_True.N[[y]]
}

max.n.rows <- lapply(Data_True.N, FUN = nrow) %>% 
  unlist() %>% 
  max()

watch.prop <- bf <- vs <- day <- effort <- array(dim = c(max.n.rows, length(Season)))
obs <- obsd.n <- array(dim = c(max.n.rows, 1, length(Season)))

for (y in 1:length(Season)){
  
  for (k in 1:nrow(Data_True.N[[y]])){
    obsd.n[k, 1, y] <- rbinom(n = 1, 
                              size = Data_True.N[[y]]$N.True[k], 
                              prob = Data_True.N[[y]]$Binom.Prob[k])
    
    obs[k,1,y] <- Data_True.N[[y]]$obs.ID[k]
    watch.prop[k, y] <- Data_True.N[[y]]$watch.prop[k]
    effort[k,y] <- Data_True.N[[y]]$effort[k]
    
    bf[k, y] <- Data_True.N[[y]]$bf[k]
    vs[k, y] <- Data_True.N[[y]]$vs[k]
    day[k, y] <- Data_True.N[[y]]$Day[k]
  }
}

# convert obs.ID to sequential number starting from 1.
unique.ID <- unique(c(unique(obs[,1,1]), unique(obs[,1,2])))
unique.ID.df <- data.frame(raw.ID = unique.ID,
                           seq.ID = 1:length(unique.ID))
#unique.ID.df[is.na(unique.ID.df$raw.ID), "seq.ID"] <- 36                           

obs.1 <- obs
for (c1 in 1:dim(obs)[1]){
  for (c2 in 1:dim(obs)[2]){
    for (c3 in 1:dim(obs)[3]){
      obs.tmp <- obs[c1,c2,c3]
      if (!is.na(obs.tmp)){
        obs.1[c1,c2,c3] <- unique.ID.df %>% 
          filter(raw.ID == obs.tmp) %>%
          select(seq.ID) %>%
          pull()
        
      } else {
        obs.1[c1,c2,c3] <- unique.ID.df %>% 
          filter(is.na(raw.ID)) %>%
          select(seq.ID) %>%
          pull()
      }
      
    }
  }
}
```


```{r run-jags, echo=FALSE, message=FALSE}
#Data_True.N$obsd.n <- obsd.n
run.date <- "2022-11-08" #Sys.Date()   # change this accordingly 2022-11-08 was with a common K

out.file.name <- paste0("RData/Pois_Binom_sim_results_", run.date, ".rds")
    
MCMC.params <- list(n.samples = 120000,
                    n.thin = 10,
                    n.burnin = 100000,
                    n.chains = 5)

jags.model <- paste0("models/model_Richards_pois_bino.txt")

jags.params <- c("OBS.RF", "OBS.Switch",
                 "BF.Switch", "BF.Fixed", 
                 "VS.Switch", "VS.Fixed",
                 "mean.prob", "mean.N", "max",
                 "Corrected.Est", "Raw.Est", "N",
                 "K", "S1", "S2", "P",
                 "log.lkhd")

jags.data <- list(  n = obsd.n, 
                    n.station = c(1,1),
                    n.year = length(Season),
                    n.obs = length(unique(na.omit(as.vector(obs)))),
                    periods = periods,
                    obs = obs.1,
                    vs = scale(vs),
                    bf = scale(bf),
                    watch.prop = watch.prop,
                    day = day,
                    effort = effort,
                    bf.raw = bf,
                    vs.raw = vs)

#max.vec = c(3000, 3000))
if (!file.exists(out.file.name)){
  
  Start_Time<-Sys.time()
  
  jm <- jagsUI::jags(jags.data,
                     inits = NULL,
                     parameters.to.save= jags.params,
                     model.file = jags.model,
                     n.chains = MCMC.params$n.chains,
                     n.burnin = MCMC.params$n.burnin,
                     n.thin = MCMC.params$n.thin,
                     n.iter = MCMC.params$n.samples,
                     DIC = T, 
                     parallel=T)
  
  Run_Time <- Sys.time() - Start_Time
  jm.sim.out <- list(jm = jm,
                     jags.data = jags.data,
                     jags.params = jags.params,
                     jags.model = jags.model,
                     MCMC.params = MCMC.params,
                     Run_Time = Run_Time)
  
  saveRDS(jm.sim.out,
          file = out.file.name)
  
} else {
  
  jm.sim.out <- readRDS(out.file.name)
}



```



#### Estimated parameters for simulated data

```{r jags-posteriors, echo=FALSE, message=FALSE, warning=FALSE}
#save.fig <- T
max.r.hat <- max(unlist(lapply(jm.sim.out$jm$Rhat, 
                               FUN = max, 
                               na.rm = T)))
#jm <- jm.out$jm
#true.values <- c(S1, S2, K, P, B0, B_BF, B_VS)
# params <- data.frame(name = param.names,
#                      value = true.values)
n.Season = length(Season)
params.to.summarize.n.Season <- c("S1", "S2", "P", "max")

# Some are common among all years
params.to.summarize.n.1 <- c("K", "mean.prob", "BF.Fixed", "VS.Fixed")

# Add year specific indices
param.names.n.Season <- lapply(params.to.summarize.n.Season,
                               FUN = function(x, n.Season){
                                 out <- vector(mode = "character", length = n.Season)
                                 for (k in 1:n.Season){
                                   out[k] <- paste0(x, "[", k, "]")
                                   
                                 }
                                 return(out)}, 
                               n.Season)

# Combine the two groups to make a vector of all parameter names
param.names <- c(unlist(param.names.n.Season),
                 params.to.summarize.n.1)

params.df <- data.frame(names = param.names,
                        value = c(NA, S1, 
                                  NA, S2, 
                                  NA, P, 
                                  NA, Max,
                                  K, 
                                  B0, B_BF, B_VS))


p.trace.sim.JAGS <- plots.trace(jm.sim.out$jm, 
                       params = param.names,
                       params.df = params.df)
p.dens.sim.JAGS <- plots.dens(jm.sim.out$jm, params = param.names)

if (save.fig){
  for (k in 1:length(param.names)){
    ggsave(plot = p.trace.sim.JAGS[[k]] + 
             geom_hline(aes(yintercept = params.df[k, "value"]),
                        color = "red", size = 1.2),
           filename = paste0("figures/", param.names[k], "_sim_trace_JAGS_", 
                             dpi.set, "dpi.png"),
           
           dpi = dpi.set, 
           device = "png",
           height = 3, width = 3, units = "in",
           bg = "white")
    
    ggsave(filename = paste0("figures/", param.names[k], "_sim_dens_JAGS_", 
                             dpi.set, "dpi.png"),
           plot = p.dens.sim.JAGS[[k]],
           dpi = dpi.set, device = "png",
           height = 3, width = 3, units = "in",
           bg = "white")
    
  }
  
}

obsd.n.sim.df <- data.frame(Season = c(rep(Season[1], jm.sim.out$jags.data$periods[1]), 
                                       rep(Season[2], jm.sim.out$jags.data$periods[2])),
                            day = c(jm.sim.out$jags.data$day[1:jm.sim.out$jags.data$periods[1],1],
                                    jm.sim.out$jags.data$day[1:jm.sim.out$jags.data$periods[2],2]),
                            n = c(jm.sim.out$jags.data$n[1:jm.sim.out$jags.data$periods[1],1,1],
                                  jm.sim.out$jags.data$n[1:jm.sim.out$jags.data$periods[2],1,2]))

mean.N.hats.sim.JAGS <- data.frame(Season = rep(Season, each = 90),
                                   Day = rep(1:90, length(Season)),
                                   Mean = as.vector(jm.sim.out$jm$mean$mean.N),
                                   LCL = as.vector(jm.sim.out$jm$q2.5$mean.N),
                                   UCL = as.vector(jm.sim.out$jm$q97.5$mean.N),
                                   #true.mean = as.vector(True.N))
                                   true.mean = as.vector(N.mean))

p.mean.N.hats.sim.JAGS <- ggplot(mean.N.hats.sim.JAGS %>% group_by(Season)) + 
  geom_ribbon(aes(x = Day, ymin = LCL, ymax = UCL),
              fill = "blue", alpha = 0.5) +
  geom_path(aes(x = Day, y = Mean)) + 
  geom_path(aes(x = Day, y = true.mean), color = "gold") +
  facet_wrap(~ Season)

if (save.fig)
  ggsave(p.mean.N.hats.sim.JAGS, 
         filename = paste0("figures/mean_N_sim_JAGS_", dpi.set, "dpi.png"),
         device = "png", dpi = dpi.set)

N.hats.sim.JAGS <- data.frame(Season = rep(Season, each = 90),
                              Day = rep(1:90, times = length(Season)),
                              Mean = as.vector(jm.sim.out$jm$mean$N),
                              LCL = as.vector(jm.sim.out$jm$q2.5$N),
                              UCL = as.vector(jm.sim.out$jm$q97.5$N),
                              true.N = as.vector(True.N))

p.N.hats.sim.JAGS <- ggplot(N.hats.sim.JAGS) + 
  geom_ribbon(aes(x = Day, ymin = LCL, ymax = UCL),
              fill = "blue", alpha = 0.5) +
  geom_path(aes(x = Day, y = Mean)) + 
  geom_path(aes(x = Day, y = true.N), color = "gold") +
  geom_point(data = obsd.n.sim.df, aes(x = day, y = n))+
  facet_wrap(~ Season)

if (save.fig)
  ggsave(p.N.hats.sim.JAGS, 
         filename = paste0("figures/N_hats_sim_JAGS_", dpi.set, "dpi.png"),
         device = "png", dpi = dpi.set)

# Simulation did not take into account the correction part so no need to look at this
# for simulation analysis. 
# corrected.N.hats.sim.JAGS <- data.frame(Season = Season,
#                                         Mean = as.vector(jm.sim.out$jm$mean$Corrected.Est),
#                                         LCL = as.vector(jm.sim.out$jm$q2.5$Corrected.Est),
#                                         UCL = as.vector(jm.sim.out$jm$q97.5$Corrected.Est))

if (save.fig)
  ggsave(p.N.hats.sim.JAGS, 
         filename = paste0("figures/N_hats_sim_JAGS_", dpi.set, "dpi.png"),
         device = "png", dpi = dpi.set)


p.trace.all.sim.JAGS <- cowplot::plot_grid(plotlist = p.trace.sim.JAGS, 
                                      ncol = 2)

if (save.fig)
  # cowplot::save_plot(p.trace.all.sim.JAGS, 
  #                    filename = "figures/trace_plots_sim_JAGS.png",
  #                    device = "png", dpi = dpi.set, bg = "white")
  
  ggsave(p.trace.all.sim.JAGS, 
         filename = paste0("figures/trace_plots_sim_JAGS_", dpi.set, "dpi.png"),
         device = "png", dpi = dpi.set, bg = "white")

```


Convergence was reached for all parameters according to the @\hat{R}$ statistic, where the maximum value was `r signif(max.r.hat, 3)`. However, trace plots of some Richards function parameters did not look ideal (Figure \@ref(fig:Figure-trace-sim-JAGS)). The observed poor conversions of S1, S2, K, and max parameters might have been caused by the mismatch between the true function (gamma) and assumed (Richards) function, where Richards functions could not match the rates of increase (S2) and decrease (S1) of the gamma function. Even for the 

For the parameters that associated with sighting probabilities (mean.prob, BF.Fixed, and VS.Fixed), MCMC samples appeared to converge and captured the true values (Figure \@ref(fig:Figure-trace-sim-JAGS)). 

```{r Figure-trace-sim-JAGS, echo=FALSE, message=FALSE, fig.cap="Trace plots of parameters. Red horizontal lines indicate the true values. Not all plots contain true values because the data generating function for one year (gamma distribution) was different from the estimation function (Richards function)."}

knitr::include_graphics(paste0("figures/trace_plots_sim_JAGS_", dpi.set, "dpi.png"))

```


Even with the apparent poor conversion of a few parameters, estimated $\bar{N}$ and $N$ were qualitatively acceptable (Figures \@ref(fig:Figure-mean-N-sim-JAGS) and \@ref(fig:Figure-N-sim-JAGS)).

```{r Figure-mean-N-sim-JAGS, echo=FALSE, message=FALSE, fig.cap = "Estimated $\bar{N}$ and their 95% CI (blue ribbon) and the true $\bar{N}$ in gold."}

knitr::include_graphics(paste0("figures/mean_N_sim_JAGS_", dpi.set, "dpi.png"))
```


```{r Figure-N-sim-JAGS, echo=FALSE, message=FALSE, fig.cap = "Estimated $N$ and their 95% CI (blue ribbon) and the true $N$ in gold."}

knitr::include_graphics(paste0("figures/N_hats_sim_JAGS_", dpi.set, "dpi.png"))
```


#### Comparison to Durban et al's method

In order to evaluate the performance of the proposed method, I compared the estimates of $N_{t,y}$ between the proposed and Durban et al. methods. The model was fitted to the simulated count data using WinBUGS code.    
             
```{r WinBugs-sim-Analysis, echo=FALSE, message=FALSE}
WinBUGS.dir <- paste0(Sys.getenv("HOME"), "/WinBUGS14")
BUGS.model <- "GW_Nmix_Orig.bugs"
#BUGS.model <- "GW_Nmix_Orig_mod.bugs"  # Lower bounds of unif distributions were changed from 0 to 0.01 - this made no difference in errors (undefined real)

#####################################################
# # The following is from WinBUGS Ver2.Rmd. It ran fine. I saved data and inits from
# # the run and saved it in an rds file. Compare data and inits.
# # This works fine!

# I still keep these lines here to use the list of parameter names for WinBUGS runs. 
worked.run.date <- "2022-10-21"   # the date that WinBUGS Ver2.Rmd was run and the output saved.
data.worked <- readRDS(paste0("RData/BUGS_data_runs_",
                              worked.run.date, ".rds"))
# # N_inits <- data.worked$N_inits
# # x <- 2
# # #
# # # # Create data list from the one that worked using just the last 2 years:
# obs <- data.worked$BUGS.data$obs[, , 7:8]
# #obs <- obs - min(obs, na.rm = T) + 1
# 
# # 36 was used for non-observer
# obs[obs==36] <- NA
# unique.obs <- sort(unique(c(unique(obs[,1,1]), unique(obs[,1,2]))))
# n.obs <- length(unique.obs)
# 
# obs.df <- data.frame(new.ID = 1:n.obs,
#                      old.ID = unique.obs)
# 
# for (k1 in 1:nrow(obs.df)){
#   for (k2 in 1:2){
#     obs[which(obs[,1,1] == obs.df[k1, "old.ID"]),1,1] <- obs.df[k1,"new.ID"]
#     obs[which(obs[,1,2] == obs.df[k1, "old.ID"]),1,2] <- obs.df[k1,"new.ID"]
#   }
# }
# 
# # #
# # N_inits <- N_inits[, 7:8]
# # #
# BUGS.data.1 <- list(n = data.worked$BUGS.data$n[, , 7:8],
#                     n.com = data.worked$BUGS.data$n.com[, , 7:8],
#                     n.sp = data.worked$BUGS.data$n.sp[, , 7:8],
#                     n.station = 1,
#                     n.year = 2,
#                     obs = obs, #data.worked$BUGS.data$obs[, 1, 7:8],
#                     n.obs = max(obs, na.rm = T), #n.obs,
#                     periods = data.worked$BUGS.data$periods[7:8],
#                     u = data.worked$BUGS.data$u[, , 7:8],
#                     vs = data.worked$BUGS.data$vs[, 7:8],
#                     bf = data.worked$BUGS.data$bf[, 7:8],
#                     day = data.worked$BUGS.data$day[, 7:8],
#                     N = data.worked$BUGS.data$N[, 7:8],
#                     N.com = data.worked$BUGS.data$N.com[, 7:8],
#                     N.sp = data.worked$BUGS.data$N.sp[, 7:8],
#                     knot = data.worked$BUGS.data$knot,
#                     n.knots = data.worked$BUGS.data$n.knots,
#                     Watch.Length = data.worked$BUGS.data$Watch.Length[,7:8])
# # 
# BUGS.inits.2 <- data.worked$BUGS.inits
# 
# bm <- bugs(data =  BUGS.data.1,
#              inits = BUGS.inits.2,
#              parameters = data.worked$parameters,
#              model.file = BUGS.model,
#              n.chains = data.worked$MCMC.params$n.chains,
#              n.iter = data.worked$MCMC.params$n.iter,
#              n.burnin = data.worked$MCMC.params$n.burnin,
#              n.thin = data.worked$MCMC.params$n.thin,
#              debug=T,
#              bugs.directory = WinBUGS.dir)
# 
# # value of bernoulli z[1,1] (or z[90,1], or z[90,2]) must be an integer - this happened after I renumbered
# # the observer IDs. 
# # Compare data and inits of this section to the next section. DONE.

#########################################################

x <- length(Season)

jags.data <- jm.sim.out$jags.data
MCMC.params <- jm.sim.out$MCMC.params  # takes about 3.6 hrs

# To make computation faster, I reduce the sampling: this ran in about 2 hrs. 
# Dated 2022-10-21 but actually ran on 2022-10-26
# MCMC.params <- list(n.samples = 60000,
#                     n.thin = 10,
#                     n.burnin = 30000,
#                     n.chains = 5)

# Adds an all zero array to the second dimension, just as it was done for the
# real data.
n <- abind(jags.data$n,
           array(data = 0,
                 dim = dim(jags.data$n)),
           along = 2)

# replace NAs with zeros
n[is.na(n)] <- 0

# the u data is whether there were observers on watch. 
# 0 counts are often associated with years/shifts with 
# no second observer. So if u=0, it will fix observation probability at 0
# obs has no NAs, but no observers were indicated by 25. 
u <- jags.data$obs
u[u != 25] <- 1
u[u == 25] <- 0

# day indicators. Need to add 1 and 90 at the end
day <- rbind(jags.data$day, matrix(NA, nrow = 2, ncol = x))

for(i in 1:x){ #Set the anchor points: days 1 and 90
  day[(jags.data$periods[i]+1):(jags.data$periods[i]+2),i] <- c(1,90)

}

#The 'data' has to be the inverse of the inits, <- ??
# with NAs for all of the estimated Ns, and 0s for the days 1 and 90
N <- matrix(NA,
            nrow = max(jags.data$periods)+2,
            ncol = x)

#True number of whales passing fixed at 0 for day 1 and 90
for(i in 1:x){
  N[(jags.data$periods[i]+1):(jags.data$periods[i]+2),i] <- 0
}

# WinBUGS gives errors when N inits are set to 0.
# Try setting them to 1 instead (seems to work):
#N_inits[which(N_inits == 0, arr.ind = T)] <- 1

Watch.Length <- rbind(jags.data$effort,
                      matrix(data = NA,
                             nrow = 2,
                             ncol = x))

obs <- abind(jags.data$obs,
             array(data = 35,
                   dim = dim(jags.data$obs)),
             along = 2)

obs[is.na(obs)] <- 35

# Should this be zeros? Watch length of day 1 and 90... 
# They are 1s in data.worked. 
for (k in 1:x){
  Watch.Length[(jags.data$periods[k]+1) : (jags.data$periods[k]+2), k] <- 1
}

##############################################################
# let's swap the first and second columns (years)
# n.1 <- array(dim = dim(n))
# n.1[,,1] <- n[,,2]
# n.1[,,2] <- n[,,1]
# 
# obs.1 <- array(dim = dim(jags.data$obs))
# obs.1[,,1] <- jags.data$obs[,,2]
# obs.1[,,2] <- jags.data$obs[,,1]
# 
# bf.1 <- cbind(jags.data$bf.raw[,2], jags.data$bf.raw[,1])
# vs.1 <- cbind(jags.data$vs.raw[,2], jags.data$vs.raw[,1])
# 
# periods.1 <- c(jags.data$periods[2], jags.data$periods[1])
# 
# day.1 <- cbind(day[,2], day[,1])
# 
# N.1 <- cbind(N[,2], N[,1])
# 
# Watch.Length.1 <- cbind(Watch.Length[,2], Watch.Length[,1])
# This one didn't work either... 
##############################################################

BUGS.data <- list(n = unname(n), #n.1, #
                  n.com = unname(n), #n.1, #
                  n.sp = unname(n), #n.1, #
                  n.station = dim(jags.data$n)[2],
                  n.year = dim(jags.data$n)[3],
                  n.obs = jags.data$n.obs,
                  periods = jags.data$periods, #periods.1, #
                  obs = obs, #obs.1, #
                  u = u,
                  vs = jags.data$vs.raw, #bf.1, #
                  bf = jags.data$bf.raw, #vs.1, #
                  day = day, #day.1, #
                  #N = N, #N.1, #   # See comments below for why these were taken out
                  #N.com = N, #N.1, #
                  #N.sp = N, #N.1, #
                  knot = c(-1.46, -1.26, -1.02, -0.78,
                           -0.58, -0.34, -0.10, 0.10,
                           0.34, 0.57, 0.78, 1.02, 1.26, 1.46),
                  n.knots = 14,
                  Watch.Length = Watch.Length) #Watch.Length.1) #


#we're going to make N a partially observed data object with anchor points at day 1 and 90
# TE: I don't know how these numbers were created... they are generally 2x n (not all)
N_inits1 <- jags.data$n[, 1, ] * 2 + 2
#N_inits2 <- jags.data$n[, 2,] * 2 + 2

# Create initial values for Ns
N_inits <- rbind(N_inits1,
                 matrix(data = NA,
                        nrow = 2,
                        ncol = x))

# Are these necessary? Rather than making NAs, should they be zeros?
# With these zeros, errors result.
for (k in 1:x){
  N_inits[(jags.data$periods[k]+1) : nrow(N_inits), k] <- NA
}

#N_inits.1 <- cbind(N_inits[,2], N_inits[,1])
BUGS.inits.1 <- function() list(mean.prob = 0.5,
                                BF.Fixed = 0,
                                VS.Fixed = 0,
                                mean.prob.sp = 0.5,
                                BF.Fixed.sp = 0,
                                VS.Fixed.sp = 0,
                                mean.prob.com = 0.5,
                                BF.Fixed.com = 0,
                                VS.Fixed.com = 0,
                                mean.beta = c(0,0,0),
                                beta.sigma = c(1,1,1),
                                BF.Switch = 1,
                                VS.Switch = 1,
                                OBS.Switch = 1,
                                sigma.Obs = 1,
                                BF.Switch.sp = 1,
                                VS.Switch.sp = 1,
                                OBS.Switch.sp = 1,
                                sigma.Obs.sp = 1,
                                BF.Switch.com = 1,
                                VS.Switch.com = 1,
                                OBS.Switch.com = 1,
                                sigma.Obs.com = 1,
                                N = N_inits, 
                                N.com = N_inits, 
                                N.sp = N_inits, 
                                beta.sp = array(data=0, dim=c(2,x)),
                                sd.b.sp = rep(1, times = x),
                                z = matrix(1, nrow=90, ncol= x))

#run.date <- "2022-10-27"
if (!file.exists(paste0("RData/WinBUGS_sim_", run.date, ".rds"))){

  Start_Time<-Sys.time()

  bm <- bugs(data = BUGS.data,
             inits = BUGS.inits.1, 
             parameters = data.worked$parameters,
             model.file = BUGS.model,
             n.chains = MCMC.params$n.chains,
             n.iter = MCMC.params$n.samples,
             n.burnin = MCMC.params$n.burnin,
             n.thin = MCMC.params$n.thin,
             debug = F,
             bugs.directory = WinBUGS.dir)

  Run_Time <- Sys.time() - Start_Time

  BUGS.out.sim <- list(BUGS.data = BUGS.data,
                       bm = bm,
                       N_inits = N_inits,
                       MCMC.params = MCMC.params,
                       BUGS.model = BUGS.model,
                       Run_Time = Run_Time,
                       Sys.env = Sys.getenv())  
  
  # the Sys.env was added after the final run on 2022-10-27. So, may not be in the output.
  
  saveRDS(BUGS.out.sim,
          paste0("RData/WinBUGS_sim_", run.date, ".rds"))
} else {
  BUGS.out.sim <- readRDS(paste0("RData/WinBUGS_sim_", run.date, ".rds"))

}

## 2022-11-08 More undefined real...
# undefined real result
# 
#  UpdaterDFreeARS.BuildHull   [000009C5H] 
# 	.denom	REAL	-inf

# I changed the True.N[1] and True.N[90] in the simulation to zeros and the error disappeared.
# 2022-11-08

###### Some bugs were worked out #######
# undefined real result was caused by not having 1 in Watch.Length for day 1 and 90
# Took me a couple days to figure it out... Still comes back with error (undefined
# real result as of 2022-10-06). It starts fine but stops while computing. This tells
# me that it must be something to do with parameter space (priors). But it works fine
# on real datasets...

# First error message of the trap is
#
#  Math.Ln   [0000018BH]
# 	.x	REAL	-inf
#
# There must be log(0) somewhere... This was fixed when N, N.com, and N.sp were
# taken out from the data. All those were NAs and seemed unnecessary. 
#
# However, the next error is the following:
#
#undefined real result
#  MathRandnum.Poisson   [000010DBH] 
# 	.floor	INTEGER	1372739575
# 	.lambda	REAL	4254980750.573238
# 	.x	INTEGER	48740688
#
# It appears that Poisson random number generator blew up. 

# All the problems were fixed after removing N, N.sp, and N.com in the data
# And, fixing a line where the index for lambda (Poisson mean) in GW_Nmix_Orig.bugs:
# Correct: log(lambda[j,t]) <- log(Watch.Length[j,t]) + selected[day[j,t],t] 
# Wrong: log(lambda[j,t]) <- log(Watch.Length[j,t]) + selected[j,t] 

# Finally, it ran on 2022-10-26. 
# The same number of MCMC runs as the jags run was completed on 2022-10-27
```

Results indicated that Durban's approach overestimated the true abundance by approximately 2.5 folds (Fig. \@ref(fig:Figure-N-sim-BUGS)). Credible intervals were wide when no counts were available. 


```{r WinBUGS-results, echo=FALSE, message=FALSE}
seasons <- c("2020", "2022")

# Extract estimated counts
Daily.Est.sim <- BUGS.out.sim$bm$sims.list$Daily.Est
sp.sim <- BUGS.out.sim$bm$sims.list$sp
com.sim <- BUGS.out.sim$bm$sims.list$com
#Corrected.Est.sim.BUGS <- BUGS.out.sim$bm$sims.list$Corrected.Est

# Each one of them is (# samples) x (90 days) x (# years)
# To plot them using ggplot's facet, I need to convert
# these into 2D dataframes of statistics (upper and lower 
# CIs, median, etc.)
# Daily.Est.list <- sp.list <- com.list <- vector(mode = "list", 
#                                                 length = dim(Daily.Est)[3])
# 
# Daily.Est.UCIs <- Daily.Est.LCIs <- vector(mode = "list",
#                                            length = dim(Daily.Est)[3])

stats.list <- vector(mode = "list",
                     length = dim(Daily.Est.sim)[3])

for (k in 1:dim(Daily.Est.sim)[3]){
  # Daily.Est.list[[k]] <- Daily.Est[,,k]
  # Daily.Est.UCIs[[k]] <- apply(Daily.Est[,,k],2,quantile,0.975)
  # Daily.Est.LCIs[[k]] <- apply(Daily.Est[,,k],2,quantile,0.275)
  # 
  # sp.list[[k]] <- sp[,,k]
  # com.list[[k]] <- com[,,k]
  
  stats.list[[k]] <- data.frame(Daily.Est.median = apply(Daily.Est.sim[,,k], 2,
                                                         median),
                                Daily.Est.LCL = apply(Daily.Est.sim[,,k], 2,
                                                      quantile,0.275),
                                Daily.Est.UCL = apply(Daily.Est.sim[,,k], 2,
                                                      quantile,0.975),
                                sp.median = apply(exp(sp.sim[,,k]), 2,
                                                  median),
                                sp.LCL = apply(exp(sp.sim[,,k]), 2,
                                               quantile,0.025),
                                sp.UCL = apply(exp(sp.sim[,,k]), 2,
                                               quantile,0.975),
                                com.median = apply(exp(com.sim[,,k]), 2,
                                                   median),
                                com.LCL = apply(exp(com.sim[,,k]), 2,
                                                quantile,0.025),
                                com.UCL = apply(exp(com.sim[,,k]), 2,
                                                quantile,0.975),
                                #total.median = apply(exp(sp.sim[,,k]), 1, sum),
                                days = 1:dim(Daily.Est.sim)[2],
                                Season = seasons[k])
}

all.stats.sim.BUGS <- do.call("rbind", stats.list) %>% group_by(Season)

p.Daily.sim.BUGS <- ggplot(data = all.stats.sim.BUGS) +
  geom_line(aes(x = days, y = Daily.Est.median)) +
  geom_ribbon(aes(x = days, 
                  ymin = Daily.Est.LCL, 
                  ymax = Daily.Est.UCL),
              fill = "darkblue", 
              alpha = 0.5) + 
  geom_line(data = N.hats.sim.JAGS,
            aes(x = Day, y = Mean)) +
  geom_ribbon(data = N.hats.sim.JAGS,
            aes(x = Day, 
                ymin = LCL,
                ymax = UCL), 
            fill = "lightblue",
            alpha = 0.5) +
  geom_path(data = N.hats.sim.JAGS,
            aes(x = Day, y = true.N),
            color = "gold") +
  geom_point(data = obsd.n.sim.df, 
             aes(x = day, y = n))+
  facet_wrap(vars(Season))+
  xlab("Days since December 1") + 
  ylab("Whales per day") +
  ylim(c(0, 700))

if (save.fig)
  ggsave(filename = paste0("figures/BUGS_daily_sim_", dpi.set, "dpi.png"),
         plot = p.Daily.sim.BUGS, device = "png", 
         dpi = dpi.set)

```



```{r Figure-N-sim-BUGS, echo=FALSE, message=FALSE, fig.cap = "Estimated $N$ and their 95% CI (dark blue ribbon) using Durban's method, new approach (light blue ribbon), the true $N$ (gold), and observed counts (black dots)."}

knitr::include_graphics(paste0("figures/BUGS_daily_sim_", dpi.set, "dpi.png"))
```

#### Reanalysis of the last 8 seasons

Data from last 8 seasons were analyzed using the new approach and the results compared to results from Durban et al's approach. 



```{r new-analysis-8yr-v2, echo=FALSE, message=FALSE}
BUGS.out <- readRDS("RData/WinBUGS_8yr_v2.rds")
out.file.name <- "RData/JAGS_pois_binom_8yr_v2_2022-10-28.rds"

jags.data.real <- list(  n = BUGS.out$jags.data$n, 
                         n.station = rep(1, dim(BUGS.out$jags.data$n)[3]),
                         n.year = dim(BUGS.out$jags.data$n)[3],
                         n.obs = BUGS.out$jags.data$n.obs,
                         periods = BUGS.out$jags.data$periods,
                         obs = BUGS.out$jags.data$obs,
                         vs = scale(BUGS.out$jags.data$vs),
                         bf = scale(BUGS.out$jags.data$bf),
                         watch.prop = (BUGS.out$jags.data$Watch.Length*24*60)/540,
                         day = BUGS.out$jags.data$day)


if (!file.exists(out.file.name)){
  
  Start_Time<-Sys.time()
  
  jm <- jagsUI::jags(jags.data.real,
                     inits = NULL,
                     parameters.to.save= jags.params,
                     model.file = jags.model,
                     n.chains = MCMC.params$n.chains,
                     n.burnin = MCMC.params$n.burnin,
                     n.thin = MCMC.params$n.thin,
                     n.iter = MCMC.params$n.samples,
                     DIC = T, 
                     parallel=T)
  
  Run_Time <- Sys.time() - Start_Time
  jm.out <- list(jm = jm,
                 jags.data = jags.data,
                 jags.params = jags.params,
                 jags.model = jags.model,
                 MCMC.params = MCMC.params,
                 Run_Time = Run_Time,
                 Sys.env = Sys.getenv())
  
  saveRDS(jm.out,
          file = out.file.name)
  
} else {
  
  jm.out <- readRDS(out.file.name)
}



```


```{r JAGS-results, echo=F,message=FALSE}
Season <- c("2006/2007", "2007/2008", "2009/2010", "2010/2011", 
            "2014/2015", "2015/2016", "2019/2020", "2021/2022")

max.r.hat <- max(unlist(lapply(jm.out$jm$Rhat, 
                               FUN = max, 
                               na.rm = T)))

# Create a vector of parameter names
# Some are year specific:
n.Season <- length(Season)
params.to.summarize.n.Season <- c("S1", "S2", "P", "max", 
                                  "Corrected.Est", "Raw.Est")

# Some are common among all years
params.to.summarize.n.1 <- c("K", "mean.prob", "BF.Fixed", "VS.fixed")

# Add year specific indices
param.names.n.Season <- lapply(params.to.summarize.n.Season,
                               FUN = function(x, n.Season){
                                 out <- vector(mode = "character", length = n.Season)
                                 for (k in 1:n.Season){
                                   out[k] <- paste0(x, "[", k, "]")
                                   
                                 }
                                 return(out)}, 
                               n.Season)

# Combine the two groups to make a vector of all parameter names
param.names <- c(unlist(param.names.n.Season),
                 params.to.summarize.n.1)

p.dens <- plots.dens(jm.out$jm, params = param.names)
p.trace <- plots.trace(jm.out$jm, params = param.names)

if (save.fig){
  for (k in 1:length(param.names)){
    ggsave(plot = p.trace[[k]] + 
             geom_hline(aes(yintercept = params.df[k, "value"]),
                        color = "red", size = 1.2),
           filename = paste0("figures/", param.names[k], "_trace_", 
                             dpi.set, "dpi.png"),
           
           dpi = dpi.set, 
           device = "png",
           height = 3, width = 3, units = "in")
    
    ggsave(filename = paste0("figures/", param.names[k], "_dens_", 
                             dpi.set, "dpi.png"),
           plot = p.dens[[k]],
           dpi = dpi.set, device = "png",
           height = 3, width = 3, units = "in")
    
  }
  
}

mean.N.hats.JAGS <- data.frame(Season = rep(Season, each = 90),
                               Day = rep(1:90, length(Season)),
                               Mean = as.vector(jm.out$jm$mean$mean.N),
                               LCL = as.vector(jm.out$jm$q2.5$mean.N),
                               UCL = as.vector(jm.out$jm$q97.5$mean.N))

N.hats.JAGS <- data.frame(Season = rep(Season, each = 90),
                          Day = rep(1:90, times = length(Season)),
                          Mean = as.vector(jm.out$jm$mean$N),
                          LCL = as.vector(jm.out$jm$q2.5$N),
                          UCL = as.vector(jm.out$jm$q97.5$N))

Corrected.Est.df.JAGS <- data.frame(Season = Season,
                                    Mean = as.vector(jm.out$jm$mean$Corrected.Est),
                                    LCL = as.vector(jm.out$jm$q2.5$Corrected.Est),
                                    UCL = as.vector(jm.out$jm$q97.5$Corrected.Est))

# get the BUGS output
# Extract estimated daily counts
Daily.Est.BUGS <- BUGS.out$BUGS_out$sims.list$Daily.Est
sp.BUGS <- BUGS.out$BUGS_out$sims.list$sp
com.BUGS <- BUGS.out$BUGS_out$sims.list$com
Corrected.Est.BUGS <- BUGS.out$BUGS_out$sims.list$Corrected.Est

stats.list <- vector(mode = "list",
                     length = dim(Daily.Est.BUGS)[3])

for (k in 1:dim(Daily.Est.BUGS)[3]){
  stats.list[[k]] <- data.frame(Daily.Est.median = apply(Daily.Est.BUGS[,,k], 2,
                                                         median),
                                Daily.Est.LCL = apply(Daily.Est.BUGS[,,k], 2,
                                                      quantile,0.275),
                                Daily.Est.UCL = apply(Daily.Est.BUGS[,,k], 2,
                                                      quantile,0.975),
                                sp.median = apply(exp(sp.BUGS[,,k]), 2,
                                                  median),
                                sp.LCL = apply(exp(sp.BUGS[,,k]), 2,
                                               quantile,0.025),
                                sp.UCL = apply(exp(sp.BUGS[,,k]), 2,
                                               quantile,0.975),
                                com.median = apply(exp(com.BUGS[,,k]), 2,
                                                   median),
                                com.LCL = apply(exp(com.BUGS[,,k]), 2,
                                                quantile,0.025),
                                com.UCL = apply(exp(com.BUGS[,,k]), 2,
                                                quantile,0.975),
                                #total.median = apply(exp(sp[,,k]), 1, sum),
                                days = 1:dim(Daily.Est.BUGS)[2],
                                Season = Season[k])
}

all.stats.BUGS <- do.call("rbind", stats.list) %>% group_by(Season)

Corrected.Est.df.BUGS <- data.frame(total.median = apply(Corrected.Est.BUGS, 
                                                         FUN = median, 
                                                         MARGIN = 2),
                                    total.LCL = apply(Corrected.Est.BUGS, 
                                                      MARGIN = 2, 
                                                      FUN = quantile, 0.025),
                                    total.UCL = apply(Corrected.Est.BUGS, 
                                                      MARGIN = 2, 
                                                      FUN = quantile, 0.975),
                                    Season = Season)

p.mean.N.hats.JAGS <- ggplot(mean.N.hats.JAGS %>% group_by(Season)) + 
  geom_ribbon(aes(x = Day, ymin = LCL, ymax = UCL),
              fill = "blue", alpha = 0.5) +
  geom_path(aes(x = Day, y = Mean)) + 

  facet_wrap(~ Season)

if (save.fig)
  ggsave(p.mean.N.hats.JAGS, 
         filename = paste0("figures/mean_N_pois_bino_", dpi.set, "dpi.png"),
         device = "png", dpi = dpi.set)

p.N.hats <- ggplot(N.hats.JAGS) + 
  geom_ribbon(aes(x = Day, 
                  ymin = LCL, 
                  ymax = UCL),
              fill = "lightblue", 
              alpha = 0.5) +
  geom_path(aes(x = Day, y = Mean)) + 
  geom_ribbon(data = all.stats.BUGS,
              aes(x = days, 
                  ymin = Daily.Est.LCL,
                  ymax = Daily.Est.UCL),
              fill = "darkblue",
              alpha = 0.5) +
  geom_path(data = all.stats.BUGS,
            aes(x = days, y = Daily.Est.median)) +
  #geom_point(data = obsd.n.df, aes(x = day, y = n))+
  facet_wrap(~ Season)

if (save.fig)
  ggsave(p.N.hats, 
         filename = paste0("figures/N_hats_BUGS_JAGS_", dpi.set, "dpi.png"),
         device = "png", dpi = dpi.set)

p.corrected.N.hats <- ggplot() + 
  geom_errorbar(data = Corrected.Est.df.JAGS,
                aes(x = Season, ymin = LCL, ymax = UCL),
                color = "lightblue") +
  geom_point(data = Corrected.Est.df.JAGS,
             aes(x = Season, y = Mean)) +
  geom_errorbar(data = Corrected.Est.df.BUGS,
                aes(x = Season, 
                    ymin = total.LCL, 
                    ymax = total.UCL),
                color = "darkblue") +
  geom_point(data = Corrected.Est.df.BUGS,
             aes(x = Season, y = total.median)) +
  xlab("")

if (save.fig)
  ggsave(p.corrected.N.hats, 
         filename = paste0("figures/corrected_N_BUGS_JAGS_", dpi.set, "dpi.png"),
         device = "png", dpi = dpi.set)




```

Convergence was reached for all parameters where the maximum $\hat{R}$ statistic was `r signif(max.r.hat, 3)`. As it was found in the analysis of simulated data, daily estimates were greater for the new approach than Durban's approach (Figure \@ref(fig:Figure-daily-N-hats)). Estimates from the new approach was more precise than those from Durban's method. As a consequence, annual estimates also were greater for Durban's method than for the new approach and precision was better for the new approach (Figure \@ref(fig:Figure-N-hats)).   


```{r Figure-daily-N-hats, echo=FALSE, message=FALSE, fig.cap = "Estimated dailyt abundance and their 95% CIs using Durban's method (dark blue) and new approach (light blue)."}

knitr::include_graphics(paste0("figures/N_hats_BUGS_JAGS_", dpi.set, "dpi.png"))
```

```{r Figure-N-hats, echo=FALSE, message=FALSE, fig.cap = "Estimated annual abundance and their 95% CIs using Durban's method (dark blue) and new approach (light blue)."}

knitr::include_graphics(paste0("figures/corrected_N_BUGS_JAGS_", dpi.set, "dpi.png"))
```
