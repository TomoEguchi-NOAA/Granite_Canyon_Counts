---
title: "R Notebook"
output: html_notebook
---

In this version, I use the new function that was used to compare Josh's and my results. 

This fix may work for all years. At least, 2015 and 2016 files were processed without any errors. Results need to be compared with Josh's outputs. 


The station information needs to be added. The data files that I have don't have that info... this needs to be fixed in the future. 


```{r}

rm(list=ls())
library(tidyverse)
library(lubridate)
source("Granite_Canyon_Counts_fcns.R")

# Do not run 2023 with this script. Use Extract_Data_2023.Rmd for 2023. 
# I ran 2023 data and seemed to work fine... 2023-10-19
# YEAR should be one of 2015, 2016, 2020, 2022, 2023 (and beyond)
YEAR <- 2015 #Enter the year of the data files

# For 2010 and 2011 (maybe in the previous years too but I don't have any of those files)
# Time is entered in decimal hours, not hh:mm:ss. So, that needs to be accommodated in
# data extraction code. 2022-10-05

```


```{r}

if (YEAR == 2023){
  FILES <- list.files(path = paste0("Data/", YEAR, "/"),
                      pattern = "EditedGW")
  
} else {
  # if FILES input was not provided, make a list of files in the directory. This should work
  # for other years 
  FILES <- list.files(paste0("Data", "/", YEAR, "/"))

}
  

all.data.list <- Data_Out.list <- all.sightings.list <- list()

# The next for loop throws back "NAs introduced by coercion" but not to worry.
# These are results of as.numeric() for the line numbers, where some lines may
# be non-numbers, e.g., "Edited" and other text. Also, some BF and VS codes are
# missing and they return warnings "in 'transmute()'..." They turn into NAs so 
# they are not problems. 

ff <- 10
for(ff in 1:length(FILES)){ 
  
  data <- get.data("Data/", YEAR, FILES = FILES, ff = ff)
  
  #Shifts <- which(data$V2 %in% c('P','E')) #start/end of all shifts
  Shifts <- which(data$V2 %in% "P") #start of all shifts
  # # if there is no "E"
  # if (length(which(data$V2 %in% "E")) == 0){
  #   i.max <- length(Shifts)
  # } else {
  #   i.max <- length(Shifts) - 1
  # }
  # 
  all.data <- Output.list <- all.sightings <- list()
  k <- 1
  for(k in 1:length(Shifts)){
    out.shift <- get.shift(YEAR, data, k)
      
    Output.list[[k]] <- out.shift$out.df
    all.sightings[[k]] <- out.shift$data  # added for Laake's analysis
    all.data[[k]] <- out.shift$data.shift  # for computing effort for Laake's analysis
  }#i
  
  Data_Out.list[[ff]] <- do.call("rbind", Output.list)
  all.sightings.list[[ff]] <- do.call("rbind", all.sightings)
  all.data.list[[ff]] <- do.call("rbind", all.data)
  
  #Sys.sleep(1)
}#ff (files loop)         

Data_Out <- do.call("rbind", Data_Out.list)
Data4Laake <- do.call("rbind", all.sightings.list) %>%
  
  mutate(key.1 = paste0(as.Date(V3, format = "%m/%d/%Y"), "_", shift, "_", key)) %>%
  dplyr::select(-c("V15", "V16", "key")) %>%
  rename(c( "Event_ID" = "V1",
            "Event_Code" = "V2",
            "Date" = "V3",
            "Time_PST" = "V4",
            "Group_ID" = "V5",
            "Bearing" = "V6",
            "Reticle" = "V7",
            "Distance" = "V8",
            "n" = "V9",
            "Observer1" = "V10",
            "Observer2" = "V11",
            "Beaufort" = "V12",
            "Visibility" = "V13",
            "Direction" = "V14",
            "Decimal_Day" = "begin",
            "Shift" = "shift",
            "Input_Filename" = "ff",
            "key" = "key.1"))

Effort4Laake <- do.call("rbind", all.data.list) %>%
  filter(key > 0) %>%
  
  mutate(key.1 = paste0(as.Date(V3, format = "%m/%d/%Y"), "_", shift, "_", key)) %>%
  dplyr::select(-c("V15", "V16", "key")) %>%
  rename(c( "Event_ID" = "V1",
            "Event_Code" = "V2",
            "Date" = "V3",
            "Time_PST" = "V4",
            "Group_ID" = "V5",
            "Bearing" = "V6",
            "Reticle" = "V7",
            "Distance" = "V8",
            "n" = "V9",
            "Observer1" = "V10",
            "Observer2" = "V11",
            "Beaufort" = "V12",
            "Visibility" = "V13",
            "Direction" = "V14",
            "Decimal_Day" = "begin",
            "Shift" = "shift",
            "Input_Filename" = "ff",
            "effort" = "effort",
            "key" = "key.1"))
```


```{r}
# Filter out short periods:

#Josh: 0.0625 is the exact watch period, but I've given some leeway. If it's less than 5 minutes short, I'm counting it
#If it's less than 10 minutes over the 1.5hrs, I'm also counting it (guessing that they forgot to log off or something)

#Entries that are less than 1.5hrs (5 minute grace period)
shift_dur_min <- 90   # 90 minutes - 5 minutes
#grace_min <- 5
# Data_Out[which((Data_Out$end - Data_Out$begin) < (shift_dur_min - grace_min)/(24*60)),]
# 
# #Entries more than 1.5hrs (5 minute grace period)
# Data_Out[which((Data_Out$end - Data_Out$begin) > (shift_dur_min + grace_min)/(24*60)),] 
# 
# #Entries more than 1.5 hrs +/- 10 min
#grace_min <- 10
# Data_Out[which(Data_Out$end - Data_Out$begin < 
#                  (shift_dur_min - grace_min)/(24*60)),]
# Data_Out[which(Data_Out$end-Data_Out$begin > 
#                  (shift_dur_min + grace_min)/(24*60)),] 

# Final data
# Remove watches that were less than 85 minutes or greater than 95 minutes:
grace_min <- 5

# For Mar 2023 analysis, I changed this to minimum duration of 30 minutes
max_dur <- 90 + grace_min
min_dur <- 90 - grace_min
#min_dur <- 30

Data_Out %>% 
  filter(dur > min_dur/(24*60) & 
           dur < max_dur/(24*60)) -> Correct_Length

Chaff <- Data_Out[which(Data_Out$end-Data_Out$begin < 
                          (shift_dur_min - grace_min)/(24*60)),]

Final_Data <- Correct_Length %>%
  filter(bf < 5, vs < 5)

WhalesDays <- Final_Data %>%
  group_by(BeginDay) %>%
  mutate(PropDay = end-begin) %>%
  summarize(TotalWatch = sum(PropDay), TotalWhales=sum(n))

ggplot(data = WhalesDays) + 
  geom_point(aes(x = as.numeric(BeginDay), y = TotalWhales/TotalWatch))
#plot(x=WhalesDays$BeginDay,y=WhalesDays$TotalWhales/WhalesDays$TotalWatch)

ShiftsPerDay <- Final_Data %>%
  group_by(BeginDay) %>%
  summarize(Watches = n())

```


```{r}
#Spot Checks:

#Check shifts that passed muster to confirm the compiled data is correct
# set.seed(1199)
# Final_Data[sample(1:196,20,replace=F),]
# 
# #Check shifts that were thrown out to make sure they deserved it
# set.seed(1200)
# Chaff[sample(1:54,10,replace=F),]


#Summary Stats for Report
Complete_Data <- Final_Data[complete.cases(Final_Data),]
Complete_Data$Eff <- Complete_Data$end - Complete_Data$begin

TotalHrs <- sum(Complete_Data$Eff)*24
TotalDays <- length(unique(floor(Complete_Data$begin)))
TotalObservers <- length(unique(Complete_Data$obs))
TotalWhales <- sum(Complete_Data$n)

WPH <- Complete_Data %>%
  mutate(DaysSinceDec1 = as.numeric(BeginDay)) %>%
  group_by(DaysSinceDec1) %>%
  summarize(TotalWhales = sum(n), 
            TotalEffort = sum(Eff), 
            WPH = sum(n)/(sum(Eff)*24)) 

out.obj <- list(Data_Out = Data_Out,
                Correct_Length = Correct_Length,
                Final_Data = Final_Data,
                Complete_Data = Complete_Data,
                WPH = WPH)

#saveRDS(out.obj, file = paste0("RData/V2_Aug2022/out_", YEAR, "_Tomo_v2.rds"))
#saveRDS(out.obj, file = paste0("RData/V2.1_Aug2022/out_", YEAR, "_Tomo_v2.rds"))
# saveRDS(out.obj, file = paste0("RData/V2.1_Oct2023/out_", YEAR, "_min", min_dur, "_Tomo_v2.rds"))
# write.csv(Data4Laake,
#           file = paste0("data/all_sightings_", YEAR, "_Tomo_v2.rds"))
# write.csv(Effort4Laake,
#          file = paste0("data/all_effort_", YEAR, "_Tomo_v2.rds"))
```

